{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\OneDrive\\maestria\\Proyecto Integrador\\proyecto_integrador_equipo_27\\.venv\\Lib\\site-packages\\InstructorEmbedding\\instructor.py:7: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import trange\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "import os\n",
    "#import dotenv\n",
    "from tqdm import tqdm\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.schema import Document\n",
    "\n",
    "## To run Hugging Face OpenSource models\n",
    "# Needs to manually install Visual C++ Tools from: https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
    "from InstructorEmbedding import INSTRUCTOR\n",
    "from langchain_community.embeddings import HuggingFaceInstructEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "#For some reason, \"context\" cant be used as input variable, it should be named as \"summaries\"\n",
    "from langchain.chains import RetrievalQAWithSourcesChain\n",
    "from langchain_ollama import OllamaLLM\n",
    "from langchain.prompts import PromptTemplate\n",
    "import warnings\n",
    "from rich import print\n",
    "import random, re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Download necessary NLTK data (run this only once)\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Suppress all warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">CUDA Available: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "CUDA Available: \u001b[3;92mTrue\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Device Name: NVIDIA GeForce RTX <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3050</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Device Name: NVIDIA GeForce RTX \u001b[1;36m3050\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Check if CUDA is available\n",
    "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "\n",
    "# Print CUDA device name\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Device Name: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">cuda\n",
       "</pre>\n"
      ],
      "text/plain": [
       "cuda\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Ensure GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define directories\n",
    "# Define the persistent directory containing the VectorDB\n",
    "script_dir =  os.getcwd()\n",
    "persistent_dir = os.path.abspath(os.path.join(script_dir,'..' ,'index', 'TestA'))\n",
    "\n",
    "# SE REQUIERE UTILIZAR EL MISMO MODELO DE SENTENCE-TRANSFORMER CON EL QUE SE CREO EL INDEX, sin ello se enfrentaran:\n",
    "#Espacios Vectoriales Diferentes:\n",
    "#\n",
    "#Cada modelo de sentence-transformer genera embeddings en su propio espacio vectorial. Estos espacios son definidos por los pesos y arquitecturas específicas de cada modelo.\n",
    "#Los embeddings generados por el modelo A no son directamente comparables con los del modelo B porque están en espacios diferentes y no alineados.\n",
    "#Incompatibilidad de Embeddings:\n",
    "#\n",
    "#Las representaciones vectoriales (embeddings) de las mismas frases pueden ser muy distintas entre modelos. Por ejemplo, una oración podría tener un vector [0.1, 0.2, 0.3] en el modelo A y [0.5, -0.1, 0.2] en el modelo B.\n",
    "#Esto significa que medidas de similitud como la similitud coseno no serán significativas, ya que los vectores no están en el mismo espacio.\n",
    "#Resultados Incorrectos o Sin Sentido:\n",
    "#\n",
    "#Al realizar consultas, las comparaciones entre embeddings del índice (modelo A) y los embeddings de la consulta (modelo B) producirán resultados erróneos.\n",
    "#Podrías obtener altas similitudes entre oraciones no relacionadas o bajas similitudes entre oraciones muy similares.\n",
    "#Pérdida de Precisión y Rendimiento:\n",
    "#\n",
    "#El rendimiento del sistema de recuperación de información se degradará significativamente.\n",
    "#Los usuarios recibirán resultados irrelevantes, lo que afecta la usabilidad y confiabilidad del sistema.\n",
    "#Consistencia en Procesamiento de Lenguaje Natural:\n",
    "#\n",
    "#Los modelos pueden tener diferentes enfoques para manejar ciertos aspectos del lenguaje, como negaciones, sarcasmo o lenguaje coloquial.\n",
    "#Esto añade otra capa de inconsistencia entre los embeddings generados por diferentes modelos.\n",
    "\n",
    "embed_model = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "\n",
    "\n",
    "# Para correr las predicciones en GPU\n",
    "model_kwargs = {'device': 'cuda:0'}  # specify GPU device\n",
    "encode_kwargs = {'normalize_embeddings': True}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set a Q&A LLM Chain to provide context and system prompts on every query\n",
    "This will run peristantly, consulting already stored vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n"
     ]
    }
   ],
   "source": [
    "##### Embedding model (sentence-transformer)\n",
    "model_name = embed_model\n",
    "model_kwargs = {'device': 'cuda:0'}  # specify GPU device\n",
    "encode_kwargs = {'normalize_embeddings': True}\n",
    "hf_embed_model = HuggingFaceInstructEmbeddings(\n",
    "    model_name=model_name,\n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs\n",
    ")\n",
    "\n",
    "##### LLM model\n",
    "# loading the Llama3 model from local\n",
    "llm_model = OllamaLLM(model=\"llama3.2\",\n",
    "                temperature=0.1,\n",
    "                num_thread=8,\n",
    "                )\n",
    "# loading the vectorstore\n",
    "vectorstore = Chroma(persist_directory=persistent_dir, embedding_function=hf_embed_model)\n",
    "# casting  the vectorstore as the retriever, taking the best 3 similarities\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\":10})\n",
    "\n",
    "# formating the docs\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "template = \"\"\"you must respond only with a 6 digit number, try to infer if the description you receive is either spanish or english and \n",
    "try to translate it before search. \n",
    "\n",
    "In the case you can't find a matching code for the description, respond with the best possible code, \n",
    "remember to respond only with a 6 digit number if there is no possible match at all, answer 'NA'. It's forbidden to answer with any text at all \".\n",
    "\n",
    "context:\n",
    "{summaries}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\"\"\"\n",
    "\n",
    "# Define the LLM chain (using the Llama3.1 model)\n",
    "llm_chain = RetrievalQAWithSourcesChain.from_chain_type(\n",
    "    llm=llm_model,\n",
    "    chain_type='stuff',\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True,  # To get both the answer and source docs\n",
    "    chain_type_kwargs={\n",
    "            \"prompt\": PromptTemplate(\n",
    "                template=template,\n",
    "                #For some reason, \"context\" cant be used as input variable, it should be named as \"summaries\"\n",
    "                input_variables=[\"question\", \"summaries\"],\n",
    "            ),\n",
    "        },\n",
    ")\n",
    "\n",
    "context = \"\"\"As a logistics shipping arrival inspector, your primary responsibility is to inspect incoming shipments and accurately classify goods \n",
    "using the Harmonized System (HS) code based on the descriptions provided in the shipping manifests. You will thoroughly review the manifest details, \n",
    "including product type, material composition, function, and intended use, to determine the correct HS code. \n",
    "\n",
    "Your task is to:\n",
    "Carefully read and analyze the product descriptions from the manifest.\n",
    "Identify key characteristics of the goods, such as \n",
    "type (e.g., electronics, textiles, machinery), \n",
    "material (e.g., plastic, metal, organic), \n",
    "and usage (e.g., household, industrial, medical).\n",
    "Use your knowledge of the HS code classification system to assign the most appropriate HS code for each product based on its description.\n",
    "Ensure compliance with international trade regulations by selecting precise codes to avoid delays or penalties.\n",
    "Remember to be thorough and accurate in your classification, as this impacts customs processing, tariffs, and legal requirements.\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">The requested item's description to search HTS code is:</span>\n",
       "sodium lignosulphonate\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;33mThe requested item's description to search HTS code is:\u001b[0m\n",
       "sodium lignosulphonate\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">The response of the LLM is:</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2831.29</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32mThe response of the LLM is:\u001b[0m\n",
       "\u001b[1;36m2831.29\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Test\n",
    "query = \"sodium lignosulphonate\"\n",
    "#query = \"lasagne\"\n",
    "\n",
    "# Execute the chain with the query\n",
    "#For some reason, \"context\" cant be used as input variable, it should be named as \"summaries\"\n",
    "result = llm_chain({\"question\": query, \"summaries\": context})\n",
    "\n",
    "print(f\"[bold yellow]The requested item's description to search HTS code is:[/bold yellow]\\n{query}\")\n",
    "print(f\"[bold green]The response of the LLM is:[/bold green]\\n{result['answer']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run 50 iterations of 30 random samples each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Results saved to ..<span style=\"color: #800080; text-decoration-color: #800080\">/data/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">LLM_predictions_comparison.csv</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Results saved to ..\u001b[35m/data/\u001b[0m\u001b[95mLLM_predictions_comparison.csv\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the CSV file\n",
    "df = pd.read_csv('../../Validation Data.csv', encoding='utf-8')\n",
    "\n",
    "# Extract the queries from the 'Raw_data_input' column\n",
    "all_queries = df[['Raw_data_input', 'Expected_output','Expected_output_two_digits', 'Expected_output_four_digits']].dropna()  # Ensure no missing values\n",
    "#all_queries = df[['Validation_input', 'Expected_output']].dropna()  # Ensure no missing values\n",
    "\n",
    "# Select 30 random queries\n",
    "selected_queries = all_queries.sample(30, random_state=0)\n",
    "\n",
    "# Create an empty list to store the results\n",
    "results = []\n",
    "\n",
    "# Clean text function to avoid garbage\n",
    "def clean_text(text):\n",
    "    text = text.lower() # Convert text to lowercase\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text) # Remove non-alphanumeric characters (keep spaces)\n",
    "    words = word_tokenize(text)  # Tokenization\n",
    "    words = [word for word in words if word not in merged_stopwords]     # Remove stopwords\n",
    "    # Lemmatization to convert the received sentence to a meaningful sentence\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    # Join words back into a sentence\n",
    "    meaningful_text = ' '.join(words)\n",
    "    return meaningful_text \n",
    "\n",
    "\n",
    "# Definir stopwords en español y las stopwords adicionales específicas del contexto\n",
    "stop_words_es = set(stopwords.words('spanish'))\n",
    "stop_words_en = set(stopwords.words('english'))\n",
    "additional_stopwords = {\n",
    "    'hs', 'code', 'hscode', 'hs-code', 'hs  code', 'pallets', 'plts', 'shipper', 'declares', 'hs code',\n",
    "    'containing', 'contains', 'meter', 'cubic', 'packages', 'load', 'loaded', 'weight', \n",
    "    'netweight', 'kg', 'kgs', 'cb', 'cbm', 'goods', 'parts', 'pieces', 'accessories', 'packing', \n",
    "    'declared', 'dangerous', 'impression', 'items', 'sheets', 'codes', \n",
    "    'sin', 'impresion', 'containers', 'pc', 'abv', 'net', 'gross', 'cif', 'aduana', 'customs', \n",
    "    'value', 'tax', 'duty', 'freight', 'port', 'terminal', 'consignee', 'consignor', 'invoice', \n",
    "    'manifest', 'quantity', 'description', 'volume', 'packaging', 'shipment', 'delivery', 'origin', \n",
    "    'destination', 'transport', 'carrier', 'export', 'import', 'tariff', 'item', 'declaration', \n",
    "    'clearance', 'documentation', 'commercial', 'charge', 'fees', 'logistics', 'shipping', \n",
    "    'container', 'unit', 'measurement', 'certification', 'palletized', 'metric', 'commodity', \n",
    "    'classification', 'entry', 'exportation', 'importation', 'bonded', 'zone', 'trade', 'license', 'bottle', 'bottles', 'cl',\n",
    "    'ancho', 'largo', 'mm', 'pcs', 'xhc', 'stc', 'uks','x','k', 'pty', 'id', 'cp', 'ncm', 'ne', 'itpa', 'zz', 'xg', 'topmag',\n",
    "    'rtmx', 'fcl', 'cf','f', 'xdc', 'pkgs'\n",
    "}\n",
    "\n",
    "# Combinar stopwords estándar con stopwords del contexto específico\n",
    "merged_stopwords = stop_words_es.union(stop_words_en).union(additional_stopwords)\n",
    "\n",
    "# Now, process each query with llm_chain\n",
    "for index, row in selected_queries.iterrows():\n",
    "    query = clean_text(row['Raw_data_input'])\n",
    "    expected_output = row['Expected_output']\n",
    "\n",
    "    # Execute the LLM chain (using a mock prediction for illustration here)\n",
    "    result = llm_chain({\"question\": query, \"summaries\": context})  # This is the actual call\n",
    "    llm_prediction = result['answer']  # Assuming LLM returns a numeric 6-digit value as the prediction\n",
    "\n",
    "    # Append the result in the required structure\n",
    "    results.append({\n",
    "        \"Raw_data_input\": row['Raw_data_input'],\n",
    "        \"Raw_data_input_processed\": query,\n",
    "        \"LLM_prediction\": llm_prediction,  # Here, the prediction from LLM\n",
    "        \"Expected_output\": expected_output,\n",
    "        \"Expected_output_two_digits\": row['Expected_output_two_digits'],\n",
    "        \"Expected_output_four_digits\": row['Expected_output_four_digits'],\n",
    "        \"Predicted_output_two_digits\": llm_prediction[:2],\n",
    "        \"Predicted_output_four_digits\": llm_prediction[:4],\n",
    "        \"CorrectMatch_two_digits\": 1 if llm_prediction[:2] == row['Expected_output_two_digits'] else 0 ,\n",
    "        \"CorrectMatch_four_digits\": 1 if llm_prediction[:4] == row['Expected_output_four_digits'] else 0 \n",
    "    })\n",
    "\n",
    "# Convert the results to a DataFrame\n",
    "result_df = pd.DataFrame(results)\n",
    "\n",
    "# Save the DataFrame to a new CSV file\n",
    "output_file_path = '../data/LLM_predictions_comparison.csv'\n",
    "result_df.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(f\"Results saved to {output_file_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
