{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the .txt file into a DataFrame\n",
    "data = pd.read_csv('..\\data\\hs_code_dictionary_extended.txt', delimiter='\\t', dtype=str)\n",
    "\n",
    "# Extract descriptions and HS codes\n",
    "descriptions = data['Description'].tolist()\n",
    "hs_codes = data['HTS code'].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\OneDrive\\maestria\\Proyecto Integrador\\proyecto_integrador_equipo_27\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\USER\\OneDrive\\maestria\\Proyecto Integrador\\proyecto_integrador_equipo_27\\.venv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 49\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m# Example query\u001b[39;00m\n\u001b[0;32m     48\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfresh apples\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 49\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43msearch_hs_code_chroma\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m description, hs_code \u001b[38;5;129;01min\u001b[39;00m results:\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDescription: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdescription\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, HS Code: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhs_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[2], line 41\u001b[0m, in \u001b[0;36msearch_hs_code_chroma\u001b[1;34m(query, top_k)\u001b[0m\n\u001b[0;32m     39\u001b[0m retrieved_data \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdocuments\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m]:\n\u001b[1;32m---> 41\u001b[0m     desc \u001b[38;5;241m=\u001b[39m \u001b[43mresult\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDescription\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     42\u001b[0m     hs_code \u001b[38;5;241m=\u001b[39m result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHS Code\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     43\u001b[0m     retrieved_data\u001b[38;5;241m.\u001b[39mappend((desc, hs_code))\n",
      "Cell \u001b[1;32mIn[2], line 41\u001b[0m, in \u001b[0;36msearch_hs_code_chroma\u001b[1;34m(query, top_k)\u001b[0m\n\u001b[0;32m     39\u001b[0m retrieved_data \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdocuments\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m]:\n\u001b[1;32m---> 41\u001b[0m     desc \u001b[38;5;241m=\u001b[39m \u001b[43mresult\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDescription\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     42\u001b[0m     hs_code \u001b[38;5;241m=\u001b[39m result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHS Code\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     43\u001b[0m     retrieved_data\u001b[38;5;241m.\u001b[39mappend((desc, hs_code))\n",
      "File \u001b[1;32m_pydevd_bundle\\\\pydevd_cython.pyx:1697\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.SafeCallWrapper.__call__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle\\\\pydevd_cython.pyx:635\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle\\\\pydevd_cython.pyx:1368\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle\\\\pydevd_cython.pyx:1311\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle\\\\pydevd_cython.pyx:495\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\USER\\OneDrive\\maestria\\Proyecto Integrador\\proyecto_integrador_equipo_27\\.venv\\Lib\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py:2197\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[1;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[0;32m   2194\u001b[0m             from_this_thread\u001b[38;5;241m.\u001b[39mappend(frame_custom_thread_id)\n\u001b[0;32m   2196\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads_suspended_single_notification\u001b[38;5;241m.\u001b[39mnotify_thread_suspended(thread_id, thread, stop_reason):\n\u001b[1;32m-> 2197\u001b[0m         keep_suspended \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrace_suspend_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_this_thread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes_tracker\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2199\u001b[0m frames_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   2201\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keep_suspended:\n\u001b[0;32m   2202\u001b[0m     \u001b[38;5;66;03m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\USER\\OneDrive\\maestria\\Proyecto Integrador\\proyecto_integrador_equipo_27\\.venv\\Lib\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py:2266\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[1;34m(self, thread, frame, event, arg, trace_suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[0;32m   2263\u001b[0m                 queue\u001b[38;5;241m.\u001b[39mput(internal_cmd)\n\u001b[0;32m   2264\u001b[0m                 wait_timeout \u001b[38;5;241m=\u001b[39m TIMEOUT_FAST\n\u001b[1;32m-> 2266\u001b[0m         \u001b[43mnotify_event\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwait_timeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2267\u001b[0m         notify_event\u001b[38;5;241m.\u001b[39mclear()\n\u001b[0;32m   2269\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\threading.py:622\u001b[0m, in \u001b[0;36mEvent.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    620\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[0;32m    621\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[1;32m--> 622\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    623\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\threading.py:324\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    322\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    323\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 324\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    325\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    326\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import chromadb\n",
    "\n",
    "# Load the sentence transformer model\n",
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "\n",
    "# Create embeddings for each description\n",
    "description_embeddings = model.encode(descriptions, convert_to_tensor=True)\n",
    "\n",
    "# Convert to list format for Chroma\n",
    "description_embeddings_list = description_embeddings.cpu().detach().numpy().tolist()\n",
    "\n",
    "# Initialize Chroma\n",
    "client = chromadb.Client()\n",
    "\n",
    "# Create or connect to a collection\n",
    "collection = client.create_collection(\"hs_codes_collection\")\n",
    "\n",
    "# Add data to Chroma (HS Code descriptions + corresponding HS Codes as metadata)\n",
    "for idx, (desc, code) in enumerate(zip(descriptions, hs_codes)):\n",
    "    collection.add(\n",
    "        embeddings=[description_embeddings_list[idx]],\n",
    "        metadatas=[{\"HTS code\": code, \"Description\": desc}],\n",
    "        ids=[str(idx)]  # Use index as ID\n",
    "    )\n",
    "\n",
    "\n",
    "def search_hs_code_chroma(query, top_k=3):\n",
    "    # Encode the query into an embedding\n",
    "    query_embedding = model.encode([query], convert_to_tensor=True).cpu().detach().numpy().tolist()\n",
    "\n",
    "    # Query Chroma for the top K results\n",
    "    results = collection.query(\n",
    "        query_embeddings=query_embedding,\n",
    "        n_results=top_k\n",
    "    )\n",
    "\n",
    "    # Extract relevant data from the search results\n",
    "    retrieved_data = []\n",
    "    for result in results['documents'][0]:\n",
    "        desc = result['Description']\n",
    "        hs_code = result['HS Code']\n",
    "        retrieved_data.append((desc, hs_code))\n",
    "\n",
    "    return retrieved_data\n",
    "\n",
    "# Example query\n",
    "query = \"fresh apples\"\n",
    "results = search_hs_code_chroma(query)\n",
    "\n",
    "for description, hs_code in results:\n",
    "    print(f\"Description: {description}, HS Code: {hs_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load a pre-trained text generation model\n",
    "generator = pipeline('text-generation', model='gpt2')\n",
    "\n",
    "def generate_response_chroma(query):\n",
    "    # Perform semantic search to retrieve the most relevant HS Code descriptions\n",
    "    retrieved_info = search_hs_code_chroma(query)\n",
    "    \n",
    "    # Format retrieved results\n",
    "    retrieved_text = \"\\n\".join([f\"{desc} (HS Code: {hs_code})\" for desc, hs_code in retrieved_info])\n",
    "    \n",
    "    # Combine query with retrieved information\n",
    "    input_text = f\"Query: {query}\\nRelevant HS Codes and Descriptions:\\n{retrieved_text}\\nResponse:\"\n",
    "    \n",
    "    # Generate a response\n",
    "    response = generator(input_text, max_length=100, num_return_sequences=1)[0]['generated_text']\n",
    "    \n",
    "    return response\n",
    "\n",
    "# Example query\n",
    "query = \"I want to import fresh apples\"\n",
    "response = generate_response_chroma(query)\n",
    "\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\OneDrive\\maestria\\Proyecto Integrador\\proyecto_integrador_equipo_27\\.venv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 23\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Example query\u001b[39;00m\n\u001b[0;32m     22\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mI want to import fresh apples\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 23\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_response_chroma\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(response)\n",
      "Cell \u001b[1;32mIn[3], line 8\u001b[0m, in \u001b[0;36mgenerate_response_chroma\u001b[1;34m(query)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_response_chroma\u001b[39m(query):\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;66;03m# Perform semantic search to retrieve the most relevant HS Code descriptions\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m     retrieved_info \u001b[38;5;241m=\u001b[39m \u001b[43msearch_hs_code_chroma\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;66;03m# Format retrieved results\u001b[39;00m\n\u001b[0;32m     11\u001b[0m     retrieved_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdesc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (HS Code: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhs_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m desc, hs_code \u001b[38;5;129;01min\u001b[39;00m retrieved_info])\n",
      "Cell \u001b[1;32mIn[2], line 41\u001b[0m, in \u001b[0;36msearch_hs_code_chroma\u001b[1;34m(query, top_k)\u001b[0m\n\u001b[0;32m     39\u001b[0m retrieved_data \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdocuments\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m]:\n\u001b[1;32m---> 41\u001b[0m     desc \u001b[38;5;241m=\u001b[39m \u001b[43mresult\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDescription\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m     42\u001b[0m     hs_code \u001b[38;5;241m=\u001b[39m result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHS Code\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     43\u001b[0m     retrieved_data\u001b[38;5;241m.\u001b[39mappend((desc, hs_code))\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load a pre-trained text generation model\n",
    "generator = pipeline('text-generation', model='gpt2')\n",
    "\n",
    "def generate_response_chroma(query):\n",
    "    # Perform semantic search to retrieve the most relevant HS Code descriptions\n",
    "    retrieved_info = search_hs_code_chroma(query)\n",
    "    \n",
    "    # Format retrieved results\n",
    "    retrieved_text = \"\\n\".join([f\"{desc} (HS Code: {hs_code})\" for desc, hs_code in retrieved_info])\n",
    "    \n",
    "    # Combine query with retrieved information\n",
    "    input_text = f\"Query: {query}\\nRelevant HS Codes and Descriptions:\\n{retrieved_text}\\nResponse:\"\n",
    "    \n",
    "    # Generate a response\n",
    "    response = generator(input_text, max_length=100, num_return_sequences=1)[0]['generated_text']\n",
    "    \n",
    "    return response\n",
    "\n",
    "# Example query\n",
    "query = \"I want to import fresh apples\"\n",
    "response = generate_response_chroma(query)\n",
    "\n",
    "print(response)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
