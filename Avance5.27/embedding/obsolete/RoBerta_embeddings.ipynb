{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\OneDrive\\Python Projects\\proyecto_integrador_equipo_27\\.venv\\Lib\\site-packages\\InstructorEmbedding\\instructor.py:7: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import trange\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from tqdm import tqdm\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.schema import Document\n",
    "from langchain_openai  import OpenAIEmbeddings\n",
    "\n",
    "## To run Hugging Face OpenSource models\n",
    "# Needs to manually install Visual C++ Tools from: https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
    "from InstructorEmbedding import INSTRUCTOR\n",
    "from langchain_community.embeddings import HuggingFaceInstructEmbeddings\n",
    "import warnings, re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Suppress all warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up embedding model to use with GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available: True\n",
      "Device Name: NVIDIA GeForce RTX 3050\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Check if CUDA is available\n",
    "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "\n",
    "# Print CUDA device name\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Device Name: {torch.cuda.get_device_name(0)}\")\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding model definition\n",
    "A technique for representing text data as numerical vectors, which can be input into machine learning models. The embedding model is responsible for converting text into these vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name C:\\Users\\USER/.cache\\torch\\sentence_transformers\\FacebookAI_roberta-large. Creating a new one with MEAN pooling.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at C:\\Users\\USER/.cache\\torch\\sentence_transformers\\FacebookAI_roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# WARNING! :Only runs with this version\n",
    "###### !pip install sentence-transformers==2.2.2  ######\n",
    "#Define the sentence-transformer model:\n",
    "\n",
    "#For English\n",
    "#sentence-transformers/LaBSE\n",
    "#embed_model = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "#embed_model = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "embed_model = \"FacebookAI/roberta-large\"\n",
    "\n",
    "\n",
    "#For Spanish \n",
    "#projecte-aina/aguila-7b\n",
    "#embed_model = \"hiiamsid/sentence_similarity_spanish_es\"\n",
    "\n",
    "#Other sentence-transformer settings\n",
    "model_kwargs = {'device': 'cuda:0'}  # specify GPU device\n",
    "encode_kwargs = {'normalize_embeddings': True}\n",
    "\n",
    "hf_embed_model = HuggingFaceInstructEmbeddings(\n",
    "    model_name=embed_model,\n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs\n",
    ")\n",
    "\n",
    "# Load environment variables from the .env file\n",
    "#load_dotenv()\n",
    "# Initialize OpenAI client with the API key from environment variables\n",
    "#open_ai_embed_model = OpenAIEmbeddings(openai_api_key= os.environ[\"OPENAI_API_KEY\"],\n",
    "#             model=\"text-embedding-3-large\", \n",
    "#             max_retries=1000,\n",
    "#             request_timeout=8,\n",
    "#             retry_min_seconds=4,\n",
    "#             show_progress_bar=True,\n",
    "#             )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TestF extended dictionary\n",
    "\n",
    "This HS Code dicitonary was scrapped from 2 different sites to increase redundancy and accuracy.\n",
    "\n",
    "PDFs scrapped from the web - https://www.wcoomd.org/en/topics/nomenclature/instrument-and-tools/hs-nomenclature-2022-edition/hs-nomenclature-2022-edition.aspx\n",
    "\n",
    "Definitions on WebSite - https://www.dripcapital.com/hts-code/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='Pure-bred breeding horses' metadata={'source': '0101.21'}\n",
      "page_content='Live horses (excluding pure-bred for breeding)' metadata={'source': '0101.29'}\n",
      "Amount of documents is:  5541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creando embeddings...: 100%|██████████| 5541/5541 [08:51<00:00, 10.42it/s]   \n"
     ]
    }
   ],
   "source": [
    "# Define the persistent directory containing the VectorDB\n",
    "script_dir =  os.getcwd()\n",
    "persistent_dir = os.path.abspath(os.path.join(script_dir,'..' ,'index', 'RobertaLarge-table'))\n",
    "\n",
    "# Importante Leer columna de codigo como string, sino se eliminan los zeros a la izquierda.\n",
    "df = pd.read_csv('..\\data\\WebScrap_CSVs\\hts_codes_WebScrapped.csv', encoding='utf-8', dtype={'HTS code': str})\n",
    "\n",
    "# Split data and metadata\n",
    "texts = df['Description'].tolist()  # This is the text data that will be embedded\n",
    "metadata = df['HTS code'].tolist()  # This is the metadata that will be stored alongside the embeddings\n",
    "\n",
    "documents = []\n",
    "for i, text in enumerate(texts):\n",
    "    document = Document(page_content=text, metadata={\"source\": metadata[i]})\n",
    "    documents.append(document)\n",
    "\n",
    "# Debug to check metadata + text\n",
    "print(documents[0])\n",
    "print(documents[1])    \n",
    "print(\"Amount of documents is: \" , len(documents))   \n",
    "\n",
    "vector_db = None\n",
    "with tqdm(total=len(documents), desc=\"Creando embeddings...\") as pbar:\n",
    "    for d in documents:\n",
    "        if vector_db:\n",
    "            vector_db.add_documents([d])\n",
    "        else:\n",
    "            #When no GPU is available\n",
    "            #vector_db = Chroma.from_documents([d],embed_model, persist_directory=persistent_dir )\n",
    "            \n",
    "            #To enable embeddings running on GPU: embedding and ingesting at the same time\n",
    "            vector_db = Chroma.from_documents([d],hf_embed_model, persist_directory=persistent_dir)\n",
    "        pbar.update(1)    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
